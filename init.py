# -*- coding: utf-8 -*-
"""Init.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yu_GZP9ha_5kdK1QOE-KUYFvPFCcRvI8
"""

import PIL
import argparse
import sys
import time
import numpy as np
import cv2
from image_classifier import ImageClassifier
from image_classifier import ImageClassifierOptions
from PIL import Image
#from tflite_model_maker.image_classifier import DataLoader
import os
from pathlib import Path
import pickle
import random
from  matplotlib import pyplot as plt
from numpy import asarray

from picamera.array import PiRGBArray


from picamera import PiCamera

# Visualization parameters
_ROW_SIZE = 10  # pixels
_LEFT_MARGIN = 10  # pixels
_TEXT_COLOR = (255, 255, 255)  # red
_FONT_SIZE = 1
_FONT_THICKNESS = 1
_FPS_AVERAGE_FRAME_COUNT = 1


def run(model: str, max_results: int, num_threads: int, enable_edgetpu: bool,
        camera_id: int, width: int, height: int) -> None:

  # Initialize the image classification model
  options = ImageClassifierOptions(
      num_threads=num_threads,
      max_results=max_results,
      enable_edgetpu=enable_edgetpu)
  #classifier = ImageClassifier(model, options)
  classifier1 = ImageClassifier('model1.tflite')
  classifier2 = ImageClassifier('model2.tflite')
  classifier3 = ImageClassifier('model3.tflite')
  
  # Variables to calculate FPS
  counter, fps = 0, 0
  start_time = time.time()

  img_data_array=[]
  dis_images=[]
  class_names=[]
  plt.figure(figsize=(2,5))
  for file in os.listdir('test'):
 
      image_path= os.path.join('test', file)
      #image= cv2.imread( image_path)
      image = Image.open(image_path)
      image = image.resize((224,224), Image.ANTIALIAS)
      image = asarray(image)
      image = np.reshape(image,(1,224,224,3))
      #image=cv2.resize(image, (224, 224))
      #image = image/255.0
      img_data_array.append(image)
      dis_images.append(cv2.resize(cv2.imread( image_path), (224, 224)))
      class_names.append(file)

  for index,rand in enumerate(random.sample(range(1, 40), 5)):
      print(rand)
      #categories = classifier.classify(img_data_array[rand])
      Final_label = ''
      categories = classifier1.classify(img_data_array[rand])
      #print('categories',categories)
      if categories[0].label == 'skin_cancer':
        categories1 = classifier2.classify(img_data_array[rand])
        Final_label = categories1[0].label
      else:
        categories2 = classifier3.classify(img_data_array[rand])
        Final_label = categories2[0].label
      x,y,w,h = 0,0,175,50

        # Draw black background rectangle
      cv2.rectangle(img_data_array[rand], (x, x), (x + w, y + h), (0,0,0), -1)

        # Add text
      #cv2.putText(image, "THICC flower", (x + int(w/10),y + int(h/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)

      cv2.putText(dis_images[rand], "True Label :" + class_names[rand], (_LEFT_MARGIN, (1) * _ROW_SIZE), cv2.FONT_HERSHEY_PLAIN,
                     0.7, _TEXT_COLOR, _FONT_THICKNESS)
      text_location = (_LEFT_MARGIN, (0 + 2) * _ROW_SIZE)
      cv2.putText(dis_images[rand], "Predicted Label : " +  categories[0].label + " - " + Final_label, text_location, cv2.FONT_HERSHEY_PLAIN,
                     0.7, _TEXT_COLOR, _FONT_THICKNESS)
      # for idx, category in enumerate(categories):
         # class_name = category.label
         # score = round(category.score, 2)
         # result_text = class_name + ' (' + str(score) + ')'
         # text_location = (_LEFT_MARGIN, (idx + 2) * _ROW_SIZE)
         # cv2.putText(img_data_array[rand], result_text, text_location, cv2.FONT_HERSHEY_PLAIN,
                     # 0.7, _TEXT_COLOR, _FONT_THICKNESS)
      cv2.imshow(str(rand) + ':' + class_names[rand],dis_images[rand])
      img = Image.fromarray(dis_images[rand],'RGB')
      img.save(str(rand) + ':'+ class_names[rand] + '.png')
      #print(result_text)
      ax=plt.subplot(2,5,index+1)
      ax.title.set_text(file)
  cv2.waitKey()
  cv2.destroyAllWindows()


def main():
  parser = argparse.ArgumentParser(
      formatter_class=argparse.ArgumentDefaultsHelpFormatter)
  parser.add_argument(
      '--model',
      help='Name of image classification model.',
      required=False,
      default='mobilenetV2_tf')
  parser.add_argument(
      '--maxResults',
      help='Max of classification results.',
      required=False,
      default=3)
  parser.add_argument(
      '--numThreads',
      help='Number of CPU threads to run the model.',
      required=False,
      default=4)
  parser.add_argument(
      '--enableEdgeTPU',
      help='Whether to run the model on EdgeTPU.',
      action='store_true',
      required=False,
      default=False)
  parser.add_argument(
      '--cameraId', help='Id of camera.', required=False, default=0)
  parser.add_argument(
      '--frameWidth',
      help='Width of frame to capture from camera.',
      required=False,
      default=640)
  parser.add_argument(
      '--frameHeight',
      help='Height of frame to capture from camera.',
      required=False,
      default=480)
  args = parser.parse_args()

  run(args.model, int(args.maxResults), int(args.numThreads),
      bool(args.enableEdgeTPU), int(args.cameraId), args.frameWidth,
      args.frameHeight)


if __name__ == '__main__':
  main()

